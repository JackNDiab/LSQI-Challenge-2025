{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01208b33-4eb6-4193-9e96-a67e15953d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "Split sizes: 9000000 500000 500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/b/by1997/.conda/envs/rl_agent_gpu/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[PK_deep] TEST (normalized space)\n",
      "  n: 500000\n",
      "  acc: 0.958718\n",
      "  masked_reg_mse_norm: 0.31668178060120855\n",
      "\n",
      "[PK_deep] TEST (physical space)\n",
      "  acc: 0.958718\n",
      "  masked_param_mse_phys: 1.9237614870071411\n",
      "\n",
      "[PD_deep] TEST (normalized space)\n",
      "  n: 500000\n",
      "  acc: 0.714184\n",
      "  masked_reg_mse_norm: 0.5159172073498169\n",
      "\n",
      "[PD_deep] TEST (physical space)\n",
      "  acc: 0.714184\n",
      "  masked_param_mse_phys: 11.98989486694336\n",
      "\n",
      "Saved outputs to ./test_outputs/*.npz\n"
     ]
    }
   ],
   "source": [
    "import os, json, glob, re\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "import TrajectoryGenerator as TG\n",
    "import ClassicalPredictor as CP\n",
    "import data_and_training as DT  # your big module (has ShardedMemmap, fit_normalizers, evaluate helpers)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def load_cfg_and_model(ckpt_path, num_classes, reg_dim, device):\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    cfg = ckpt[\"cfg\"]\n",
    "\n",
    "    model = CP.MultiTaskTransformer(\n",
    "        input_dim=2,\n",
    "        num_classes=num_classes,\n",
    "        reg_dim=reg_dim,\n",
    "        d_model=cfg[\"d_model\"],\n",
    "        nhead=cfg[\"nhead\"],\n",
    "        num_layers=cfg[\"num_layers\"],\n",
    "        dim_feedforward=cfg[\"dim_feedforward\"],\n",
    "        dropout=cfg[\"dropout\"],\n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    model.eval()\n",
    "    return model, cfg, ckpt\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def masked_mse_norm(yhat, ytrue, mask):\n",
    "    # yhat,ytrue,mask: torch tensors (B,D)\n",
    "    diff2 = (yhat - ytrue) ** 2\n",
    "    diff2 = diff2 * mask\n",
    "    denom = mask.sum().clamp_min(1.0)\n",
    "    return float(diff2.sum().item() / denom.item())\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_on_loader(model, loader, device, times_t, y_norm_obj):\n",
    "    all_pred_cls = []\n",
    "    all_true_cls = []\n",
    "    all_pred_params = []\n",
    "    all_true_params = []\n",
    "    all_masks = []\n",
    "\n",
    "    for x, y_cls, y_reg_norm, y_mask in loader:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "        y_cls = y_cls.to(device, non_blocking=True)\n",
    "        y_reg_norm = y_reg_norm.to(device, non_blocking=True)\n",
    "        y_mask = y_mask.to(device, non_blocking=True)\n",
    "\n",
    "        logits, yhat_reg_norm = model(x, times_t)\n",
    "        pred_cls = logits.argmax(dim=1)\n",
    "\n",
    "        # move to cpu numpy\n",
    "        pred_cls_np = pred_cls.cpu().numpy()\n",
    "        true_cls_np = y_cls.cpu().numpy()\n",
    "        mask_np = y_mask.cpu().numpy()\n",
    "\n",
    "        yhat_np = yhat_reg_norm.cpu().numpy()\n",
    "        ytrue_np = y_reg_norm.cpu().numpy()\n",
    "\n",
    "        # invert normalized -> physical using mask\n",
    "        pred_params = np.stack([y_norm_obj.inverse_one(yhat_np[i], mask_np[i]) for i in range(len(yhat_np))])\n",
    "        true_params = np.stack([y_norm_obj.inverse_one(ytrue_np[i], mask_np[i]) for i in range(len(ytrue_np))])\n",
    "\n",
    "        all_pred_cls.append(pred_cls_np)\n",
    "        all_true_cls.append(true_cls_np)\n",
    "        all_pred_params.append(pred_params)\n",
    "        all_true_params.append(true_params)\n",
    "        all_masks.append(mask_np)\n",
    "\n",
    "    return {\n",
    "        \"pred_cls\": np.concatenate(all_pred_cls),\n",
    "        \"true_cls\": np.concatenate(all_true_cls),\n",
    "        \"pred_params\": np.concatenate(all_pred_params, axis=0),\n",
    "        \"true_params\": np.concatenate(all_true_params, axis=0),\n",
    "        \"mask\": np.concatenate(all_masks, axis=0),\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_test(model, ds, idx_te, device, times_t, name=\"\"):\n",
    "    dl_te = DataLoader(\n",
    "        Subset(ds, idx_te.tolist()),\n",
    "        batch_size=1024,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    # Compute accuracy + normalized masked MSE directly from model outputs/targets\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    reg_mse_sum = 0.0\n",
    "    batches = 0\n",
    "\n",
    "    ce = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y_cls, y_reg_norm, y_mask in dl_te:\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            y_cls = y_cls.to(device, non_blocking=True)\n",
    "            y_reg_norm = y_reg_norm.to(device, non_blocking=True)\n",
    "            y_mask = y_mask.to(device, non_blocking=True)\n",
    "\n",
    "            logits, yhat_reg_norm = model(x, times_t)\n",
    "            pred = logits.argmax(dim=1)\n",
    "\n",
    "            correct += int((pred == y_cls).sum().item())\n",
    "            total += int(x.size(0))\n",
    "\n",
    "            reg_mse_sum += masked_mse_norm(yhat_reg_norm, y_reg_norm, y_mask) * x.size(0)\n",
    "            batches += 1\n",
    "\n",
    "    acc = correct / max(total, 1)\n",
    "    reg_mse_norm_avg = reg_mse_sum / max(total, 1)\n",
    "\n",
    "    print(f\"\\n[{name}] TEST (normalized space)\")\n",
    "    print(\"  n:\", total)\n",
    "    print(\"  acc:\", acc)\n",
    "    print(\"  masked_reg_mse_norm:\", reg_mse_norm_avg)\n",
    "\n",
    "    return dl_te, {\"acc\": acc, \"masked_reg_mse_norm\": reg_mse_norm_avg}\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Main\n",
    "# ----------------------------\n",
    "def main():\n",
    "    BASE_DIR = \"./dataset\"\n",
    "    SPLITS_NPZ = \"./dataset/splits_90_5_5_seed123.npz\"\n",
    "\n",
    "    # Your deep-run best checkpoints:\n",
    "    PK_CKPT = \"./long_runs/pk_deep/PK_long_deep_best.pt\"\n",
    "    PD_CKPT = \"./long_runs/pd_deep/PD_long_deep_best.pt\"\n",
    "\n",
    "    # Normalizer refit settings (must match what you used in training)\n",
    "    FIT_N = 200_000\n",
    "    PK_NORM_SEED = 1\n",
    "    PD_NORM_SEED = 2\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device:\", device)\n",
    "\n",
    "    # Discover shards\n",
    "    shards = DT.discover_mpirank_shards(BASE_DIR)\n",
    "\n",
    "    # Load splits\n",
    "    spl = np.load(SPLITS_NPZ)\n",
    "    idx_tr = spl[\"idx_tr\"].astype(np.int64)\n",
    "    idx_va = spl[\"idx_va\"].astype(np.int64)\n",
    "    idx_te = spl[\"idx_te\"].astype(np.int64)\n",
    "\n",
    "    print(\"Split sizes:\", len(idx_tr), len(idx_va), len(idx_te))\n",
    "\n",
    "    # =========================\n",
    "    # PK: build memmaps + norms + dataset + model\n",
    "    # =========================\n",
    "    X_pk = DT.ShardedMemmap(shards, \"X_pk.npy\")\n",
    "    y_pk_cls = DT.ShardedMemmap(shards, \"y_pk_cls.npy\")\n",
    "    y_pk_reg = DT.ShardedMemmap(shards, \"y_pk_reg.npy\")\n",
    "    y_pk_mask = DT.ShardedMemmap(shards, \"y_pk_mask.npy\")\n",
    "\n",
    "    xnorm_pk, ynorm_pk = DT.fit_normalizers(\n",
    "        dataset_kind=\"pk\", shard_dirs=shards, train_idx=idx_tr,\n",
    "        fit_n=FIT_N, seed=PK_NORM_SEED\n",
    "    )\n",
    "    ds_pk = DT.ShardedMultiTaskSeqDataset(X_pk, y_pk_cls, y_pk_reg, y_pk_mask, xnorm_pk, ynorm_pk)\n",
    "\n",
    "    pk_times_t = torch.tensor(TG.PK_TIMES, dtype=torch.float32, device=device)\n",
    "\n",
    "    pk_model, pk_cfg, _ = load_cfg_and_model(PK_CKPT, num_classes=10, reg_dim=TG.PK_PARAM_DIM, device=device)\n",
    "\n",
    "    dl_pk_te, pk_metrics = evaluate_test(pk_model, ds_pk, idx_te, device, pk_times_t, name=\"PK_deep\")\n",
    "\n",
    "    pk_out = infer_on_loader(pk_model, dl_pk_te, device, pk_times_t, ynorm_pk)\n",
    "\n",
    "    pk_acc = (pk_out[\"pred_cls\"] == pk_out[\"true_cls\"]).mean()\n",
    "    diff2 = (pk_out[\"pred_params\"] - pk_out[\"true_params\"]) ** 2\n",
    "    m = pk_out[\"mask\"]\n",
    "    pk_mse_phys = float((diff2 * m).sum() / max(m.sum(), 1.0))\n",
    "\n",
    "    print(\"\\n[PK_deep] TEST (physical space)\")\n",
    "    print(\"  acc:\", float(pk_acc))\n",
    "    print(\"  masked_param_mse_phys:\", pk_mse_phys)\n",
    "\n",
    "    # =========================\n",
    "    # PD: build memmaps + norms + dataset + model\n",
    "    # =========================\n",
    "    X_pd = DT.ShardedMemmap(shards, \"X_pd.npy\")\n",
    "    y_pd_cls = DT.ShardedMemmap(shards, \"y_pd_cls.npy\")\n",
    "    y_pd_reg = DT.ShardedMemmap(shards, \"y_pd_reg.npy\")\n",
    "    y_pd_mask = DT.ShardedMemmap(shards, \"y_pd_mask.npy\")\n",
    "\n",
    "    xnorm_pd, ynorm_pd = DT.fit_normalizers(\n",
    "        dataset_kind=\"pd\", shard_dirs=shards, train_idx=idx_tr,\n",
    "        fit_n=FIT_N, seed=PD_NORM_SEED\n",
    "    )\n",
    "    ds_pd = DT.ShardedMultiTaskSeqDataset(X_pd, y_pd_cls, y_pd_reg, y_pd_mask, xnorm_pd, ynorm_pd)\n",
    "\n",
    "    pd_times_t = torch.tensor(TG.PD_TIMES, dtype=torch.float32, device=device)\n",
    "\n",
    "    pd_model, pd_cfg, _ = load_cfg_and_model(PD_CKPT, num_classes=10, reg_dim=TG.PD_PARAM_DIM, device=device)\n",
    "\n",
    "    dl_pd_te, pd_metrics = evaluate_test(pd_model, ds_pd, idx_te, device, pd_times_t, name=\"PD_deep\")\n",
    "\n",
    "    pd_out = infer_on_loader(pd_model, dl_pd_te, device, pd_times_t, ynorm_pd)\n",
    "\n",
    "    pd_acc = (pd_out[\"pred_cls\"] == pd_out[\"true_cls\"]).mean()\n",
    "    diff2 = (pd_out[\"pred_params\"] - pd_out[\"true_params\"]) ** 2\n",
    "    m = pd_out[\"mask\"]\n",
    "    pd_mse_phys = float((diff2 * m).sum() / max(m.sum(), 1.0))\n",
    "\n",
    "    print(\"\\n[PD_deep] TEST (physical space)\")\n",
    "    print(\"  acc:\", float(pd_acc))\n",
    "    print(\"  masked_param_mse_phys:\", pd_mse_phys)\n",
    "\n",
    "    # =========================\n",
    "    # Optional: save predictions\n",
    "    # =========================\n",
    "    os.makedirs(\"./test_outputs\", exist_ok=True)\n",
    "    np.savez(\"./test_outputs/pk_deep_test_preds.npz\", **pk_out)\n",
    "    np.savez(\"./test_outputs/pd_deep_test_preds.npz\", **pd_out)\n",
    "    print(\"\\nSaved outputs to ./test_outputs/*.npz\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe38bed5-7e7f-4cce-a12a-742ded3159c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MY_GPU",
   "language": "python",
   "name": "rl_agent_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
