{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09dc40a1-09f4-4302-a12b-7248c337d09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PK] most popular class = pk_2c_iv_infusion (id=5), counts=[0, 0, 0, 0, 0, 36, 0, 0, 0, 0]\n",
      "[PD] most popular class = pd_indirect_inhib_kin (id=5), counts=[1, 1, 3, 0, 2, 35, 3, 1, 1, 1]\n",
      "\n",
      "[PD] Forced class = pd_indirect_inhib_kin\n",
      "  ID   1: R0=14.5132, IC50=15.9307, kin=1.96493, kout=0.135555\n",
      "  ID   2: R0=10.6281, IC50=19.0742, kin=1.45929, kout=0.137421\n",
      "  ID   3: R0=5.65982, IC50=18.6728, kin=0.988865, kout=0.174128\n",
      "  ID   4: R0=7.90742, IC50=17.4443, kin=1.10284, kout=0.139295\n",
      "  ID   5: R0=7.82976, IC50=18.4151, kin=0.939613, kout=0.119909\n",
      "  ID   6: R0=10.8586, IC50=17.2419, kin=1.45656, kout=0.134096\n",
      "  ID   7: R0=10.0962, IC50=16.8776, kin=1.36391, kout=0.135386\n",
      "  ID   8: R0=8.83373, IC50=16.3224, kin=1.03562, kout=0.117117\n",
      "  ID   9: R0=9.11767, IC50=17.6436, kin=0.649201, kout=0.0710426\n",
      "  ID  10: R0=7.01487, IC50=18.6815, kin=0.899225, kout=0.128112\n",
      "  ID  11: R0=10.5496, IC50=17.0292, kin=1.31056, kout=0.124294\n",
      "  ID  12: R0=6.12399, IC50=18.0029, kin=0.707646, kout=0.115445\n",
      "  ID  13: R0=8.16815, IC50=9.91998, kin=1.00021, kout=0.12207\n",
      "  ID  14: R0=5.81993, IC50=14.2583, kin=0.603017, kout=0.103291\n",
      "  ID  15: R0=7.80302, IC50=10.1411, kin=0.704607, kout=0.0898151\n",
      "  ID  16: R0=6.64176, IC50=14.0052, kin=0.708352, kout=0.106303\n",
      "  ID  17: R0=10.0459, IC50=5.8, kin=0.866897, kout=0.085865\n",
      "  ID  18: R0=9.2329, IC50=5.86106, kin=1.09647, kout=0.118099\n",
      "  ID  19: R0=6.45357, IC50=9.1277, kin=0.491863, kout=0.0757773\n",
      "  ID  20: R0=9.06487, IC50=7.82459, kin=1.14199, kout=0.125262\n",
      "  ID  21: R0=5.64782, IC50=18.4403, kin=0.703792, kout=0.124476\n",
      "  ID  22: R0=8.69216, IC50=5.94862, kin=0.932516, kout=0.106656\n",
      "  ID  23: R0=8.82217, IC50=7.77017, kin=1.11407, kout=0.125695\n",
      "  ID  24: R0=11.2652, IC50=5.29031, kin=1.19116, kout=0.105412\n",
      "  ID  25: R0=6.9589, IC50=10.5324, kin=0.581227, kout=0.0830336\n",
      "  ID  26: R0=7.11877, IC50=11.5449, kin=0.834956, kout=0.116699\n",
      "  ID  27: R0=7.87187, IC50=8.57387, kin=0.841176, kout=0.106136\n",
      "  ID  28: R0=9.94545, IC50=8.57555, kin=1.53746, kout=0.153905\n",
      "  ID  29: R0=7.77332, IC50=9.92839, kin=0.891103, kout=0.114039\n",
      "  ID  30: R0=8.51527, IC50=7.01702, kin=0.744779, kout=0.0869137\n",
      "  ID  31: R0=9.18308, IC50=6.17562, kin=0.792048, kout=0.0857726\n",
      "  ID  32: R0=10.4284, IC50=7.60046, kin=1.16907, kout=0.111695\n",
      "  ID  33: R0=8.15826, IC50=6.84841, kin=0.655634, kout=0.0798875\n",
      "  ID  34: R0=9.08235, IC50=12.3713, kin=1.15234, kout=0.126366\n",
      "  ID  35: R0=11.2793, IC50=5.68081, kin=1.26338, kout=0.111578\n",
      "  ID  36: R0=8.05426, IC50=6.99334, kin=0.80066, kout=0.0988922\n",
      "  ID  37: R0=9.70939, IC50=5.96555, kin=0.673772, kout=0.0690987\n",
      "  ID  38: R0=6.35658, IC50=9.98487, kin=0.340654, kout=0.0533884\n",
      "  ID  39: R0=10.1958, IC50=6.42176, kin=0.877816, kout=0.0856847\n",
      "  ID  40: R0=10.9177, IC50=6.37754, kin=0.783878, kout=0.0716029\n",
      "  ID  41: R0=6.98171, IC50=14.7362, kin=0.513361, kout=0.0732978\n",
      "  ID  42: R0=10.8253, IC50=5.46993, kin=0.78377, kout=0.0721321\n",
      "  ID  43: R0=9.70403, IC50=6.0422, kin=0.554729, kout=0.0569282\n",
      "  ID  44: R0=7.64511, IC50=8.3267, kin=0.73709, kout=0.0959067\n",
      "  ID  45: R0=6.9023, IC50=9.25089, kin=0.407384, kout=0.058794\n",
      "  ID  46: R0=11.0049, IC50=5.79541, kin=0.853433, kout=0.0773577\n",
      "  ID  47: R0=6.67225, IC50=8.88315, kin=0.572351, kout=0.0854507\n",
      "  ID  48: R0=10.6003, IC50=6.02204, kin=0.750232, kout=0.0704813\n",
      "\n",
      "[PK] Forced class = pk_2c_iv_infusion\n",
      "  ID  13: CL=0.0663582, Vc=1.46113, Vp=8.63659, Q=0.403122, tau=4.38695\n",
      "  ID  14: CL=0.0805849, Vc=1.26253, Vp=9.26489, Q=0.468095, tau=4.77175\n",
      "  ID  15: CL=0.0359619, Vc=1.16973, Vp=7.97638, Q=0.32806, tau=3.43686\n",
      "  ID  16: CL=0.0674138, Vc=1.26512, Vp=6.23057, Q=0.480143, tau=3.59571\n",
      "  ID  17: CL=0.0638222, Vc=1.31041, Vp=5.30866, Q=0.250983, tau=3.93481\n",
      "  ID  18: CL=0.0457203, Vc=1.33782, Vp=7.4209, Q=0.357786, tau=3.4317\n",
      "  ID  19: CL=0.0367547, Vc=1.27239, Vp=8.6611, Q=0.646642, tau=3.51968\n",
      "  ID  20: CL=0.0296971, Vc=0.976416, Vp=6.10603, Q=0.364555, tau=2.83182\n",
      "  ID  21: CL=0.103202, Vc=1.42973, Vp=8.68053, Q=0.515724, tau=5.10604\n",
      "  ID  22: CL=0.0507858, Vc=1.51582, Vp=10.3396, Q=0.992212, tau=5.20437\n",
      "  ID  23: CL=0.0290887, Vc=1.13947, Vp=6.40888, Q=0.243123, tau=3.47857\n",
      "  ID  24: CL=0.0462579, Vc=1.53925, Vp=12.483, Q=1.11667, tau=5.02895\n",
      "  ID  25: CL=0.0867329, Vc=1.3948, Vp=7.90156, Q=0.231752, tau=4.55186\n",
      "  ID  26: CL=0.0417398, Vc=1.21955, Vp=6.34366, Q=0.30396, tau=4.19903\n",
      "  ID  27: CL=0.049357, Vc=1.26034, Vp=6.19412, Q=0.28044, tau=4.16123\n",
      "  ID  28: CL=0.0663684, Vc=1.45238, Vp=9.41664, Q=0.318851, tau=5.4754\n",
      "  ID  29: CL=0.0567744, Vc=1.33125, Vp=6.51103, Q=0.27845, tau=4.88904\n",
      "  ID  30: CL=0.0308552, Vc=1.37751, Vp=7.73322, Q=0.235993, tau=5.47227\n",
      "  ID  31: CL=0.0290959, Vc=1.35101, Vp=7.2357, Q=0.336394, tau=5.41692\n",
      "  ID  32: CL=0.056772, Vc=1.40314, Vp=8.09569, Q=0.191969, tau=5.01639\n",
      "  ID  33: CL=0.0409632, Vc=1.2698, Vp=6.80132, Q=0.145318, tau=4.53145\n",
      "  ID  34: CL=0.0336624, Vc=1.31189, Vp=6.95787, Q=0.19154, tau=4.9131\n",
      "  ID  35: CL=0.0479368, Vc=1.47161, Vp=9.80134, Q=0.483757, tau=5.41718\n",
      "  ID  36: CL=0.0313232, Vc=1.34592, Vp=9.43133, Q=0.416218, tau=5.03786\n",
      "  ID  37: CL=0.0585649, Vc=1.57053, Vp=9.11128, Q=0.303976, tau=6.97797\n",
      "  ID  38: CL=0.065882, Vc=1.43185, Vp=9.9006, Q=0.246936, tau=6.30237\n",
      "  ID  39: CL=0.0816135, Vc=1.12149, Vp=8.32729, Q=0.37107, tau=5.91223\n",
      "  ID  40: CL=0.0555986, Vc=1.5003, Vp=10.1082, Q=0.185343, tau=6.33248\n",
      "  ID  41: CL=0.0450725, Vc=1.26377, Vp=7.11761, Q=0.145037, tau=4.83621\n",
      "  ID  42: CL=0.0893119, Vc=1.28685, Vp=9.60524, Q=0.382974, tau=6.92156\n",
      "  ID  43: CL=0.0320932, Vc=1.25071, Vp=7.12708, Q=0.232724, tau=5.18758\n",
      "  ID  44: CL=0.0718407, Vc=1.26618, Vp=8.50769, Q=0.4244, tau=6.11996\n",
      "  ID  45: CL=0.0298786, Vc=1.23913, Vp=6.92317, Q=0.244063, tau=5.07098\n",
      "  ID  46: CL=0.0575009, Vc=1.55493, Vp=10.7582, Q=0.588923, tau=6.78823\n",
      "  ID  47: CL=0.0340525, Vc=1.29048, Vp=7.79833, Q=0.484419, tau=5.502\n",
      "  ID  48: CL=0.0364823, Vc=1.36217, Vp=8.27215, Q=0.396345, tau=5.82041\n",
      "\n",
      "[PD] Summary ranges\n",
      "\n",
      "Parameter ranges (percentiles) for forced class:\n",
      "      R0: p5=5.92635  p50=8.75716  p95=11.1741\n",
      "    IC50: p5=5.72092  p50=9.1893  p95=18.5914\n",
      "     kin: p5=0.499387  p50=0.847305  p95=1.45833\n",
      "    kout: p5=0.0624007  p50=0.10622  p95=0.138639\n",
      "\n",
      "[PK] Summary ranges\n",
      "\n",
      "Parameter ranges (percentiles) for forced class:\n",
      "      CL: p5=0.0295468  p50=0.0486469  p95=0.0873776\n",
      "      Vc: p5=1.13498  p50=1.32157  p95=1.54317\n",
      "      Vp: p5=6.1721  p50=8.03603  p95=10.4442\n",
      "       Q: p5=0.175337  p50=0.332227  p95=0.733034\n",
      "     tau: p5=3.43557  p50=5.0334  p95=6.82156\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import ClassicalPredictor as CP\n",
    "import TrajectoryGenerator as TG\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Normalizer reconstruction\n",
    "# -------------------------\n",
    "class XNorm:\n",
    "    def __init__(self, mean, std, log1p=True, eps=1e-6):\n",
    "        self.mean = np.asarray(mean, dtype=np.float32)\n",
    "        self.std  = np.maximum(np.asarray(std, dtype=np.float32), eps)\n",
    "        self.log1p = bool(log1p)\n",
    "\n",
    "    def transform(self, X_NTxC: np.ndarray) -> np.ndarray:\n",
    "        X = X_NTxC.astype(np.float32, copy=False)\n",
    "        if self.log1p:\n",
    "            X = np.log1p(np.clip(X, 0.0, None))\n",
    "        return (X - self.mean[None, None, :]) / self.std[None, None, :]\n",
    "\n",
    "\n",
    "class YNorm:\n",
    "    def __init__(self, mean, std, eps=1e-12):\n",
    "        self.mean = np.asarray(mean, dtype=np.float32)\n",
    "        self.std  = np.maximum(np.asarray(std, dtype=np.float32), 1e-6)\n",
    "        self.eps = eps\n",
    "\n",
    "    def inverse(self, y_norm_NxD: np.ndarray, mask_NxD: np.ndarray) -> np.ndarray:\n",
    "        y_norm_NxD = y_norm_NxD.astype(np.float32, copy=False)\n",
    "        mask_NxD   = mask_NxD.astype(np.float32, copy=False)\n",
    "\n",
    "        used = mask_NxD > 0.5\n",
    "        z = y_norm_NxD * self.std[None, :] + self.mean[None, :]\n",
    "        out = np.zeros_like(y_norm_NxD, dtype=np.float32)\n",
    "        out[used] = np.exp(z[used])\n",
    "        return out\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Load ckpt + build model\n",
    "# -------------------------\n",
    "def load_ckpt_build_model(ckpt_path: str, device, num_classes: int, reg_dim: int):\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    cfg = ckpt[\"cfg\"]\n",
    "\n",
    "    model = CP.MultiTaskTransformer(\n",
    "        input_dim=2,\n",
    "        num_classes=num_classes,\n",
    "        reg_dim=reg_dim,\n",
    "        d_model=cfg[\"d_model\"],\n",
    "        nhead=cfg[\"nhead\"],\n",
    "        num_layers=cfg[\"num_layers\"],\n",
    "        dim_feedforward=cfg[\"dim_feedforward\"],\n",
    "        dropout=cfg[\"dropout\"],\n",
    "    ).to(device)\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    model.eval()\n",
    "\n",
    "    x_norm = None\n",
    "    y_norm = None\n",
    "    if ckpt.get(\"x_norm\") is not None:\n",
    "        x_norm = XNorm(\n",
    "            mean=ckpt[\"x_norm\"][\"mean\"],\n",
    "            std=ckpt[\"x_norm\"][\"std\"],\n",
    "            log1p=ckpt[\"x_norm\"].get(\"log1p\", True),\n",
    "        )\n",
    "    if ckpt.get(\"y_norm\") is not None:\n",
    "        y_norm = YNorm(\n",
    "            mean=ckpt[\"y_norm\"][\"mean\"],\n",
    "            std=ckpt[\"y_norm\"][\"std\"],\n",
    "        )\n",
    "\n",
    "    return model, cfg, x_norm, y_norm\n",
    "\n",
    "\n",
    "def ensure_times(times_NxT: np.ndarray, expected_T: int):\n",
    "    if times_NxT.shape[1] != expected_T:\n",
    "        raise ValueError(f\"Expected T={expected_T} but got {times_NxT.shape[1]}\")\n",
    "    return times_NxT[0].astype(np.float32)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Step 1: predict classes\n",
    "# -------------------------\n",
    "def predict_class_probs(arr_Nx3xT, model, device, times_T, x_norm, batch_size=256):\n",
    "    # features: (N,T,2)\n",
    "    X = np.transpose(arr_Nx3xT[:, 1:3, :], (0, 2, 1)).astype(np.float32)\n",
    "    if x_norm is not None:\n",
    "        X = x_norm.transform(X)\n",
    "\n",
    "    times_t = torch.tensor(times_T, dtype=torch.float32, device=device)\n",
    "\n",
    "    N = X.shape[0]\n",
    "    probs = []\n",
    "    for s in range(0, N, batch_size):\n",
    "        e = min(N, s + batch_size)\n",
    "        xb = torch.from_numpy(X[s:e]).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits, _ = model(xb, times_t)\n",
    "            pb = F.softmax(logits, dim=1).cpu().numpy()\n",
    "        probs.append(pb)\n",
    "    return np.concatenate(probs, axis=0)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Step 2: force params under one class for ALL\n",
    "# -------------------------\n",
    "def force_class_params_for_all(arr_Nx3xT, model, device, times_T, x_norm, y_norm,\n",
    "                               class_param_masks_KxD, forced_class_id: int, batch_size=256):\n",
    "    X = np.transpose(arr_Nx3xT[:, 1:3, :], (0, 2, 1)).astype(np.float32)\n",
    "    if x_norm is not None:\n",
    "        X = x_norm.transform(X)\n",
    "\n",
    "    times_t = torch.tensor(times_T, dtype=torch.float32, device=device)\n",
    "\n",
    "    N = X.shape[0]\n",
    "    D = class_param_masks_KxD.shape[1]\n",
    "    forced_mask_D = class_param_masks_KxD[forced_class_id].astype(np.float32)  # (D,)\n",
    "    forced_mask_NxD = np.tile(forced_mask_D[None, :], (N, 1)).astype(np.float32)\n",
    "\n",
    "    yphys_all = np.zeros((N, D), dtype=np.float32)\n",
    "    for s in range(0, N, batch_size):\n",
    "        e = min(N, s + batch_size)\n",
    "        xb = torch.from_numpy(X[s:e]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits, yhat_norm = model(xb, times_t)\n",
    "            yhn = yhat_norm.cpu().numpy().astype(np.float32)  # (B,D)\n",
    "\n",
    "        mask_be = forced_mask_NxD[s:e]  # (B,D)\n",
    "        if y_norm is not None:\n",
    "            yphys = y_norm.inverse(yhn, mask_be)\n",
    "        else:\n",
    "            yphys = yhn\n",
    "        yphys_all[s:e] = yphys\n",
    "\n",
    "    return {\n",
    "        \"forced_class_id\": int(forced_class_id),\n",
    "        \"forced_mask\": forced_mask_D,\n",
    "        \"forced_params_phys\": yphys_all,\n",
    "    }\n",
    "\n",
    "\n",
    "def print_per_trajectory_params(task_name: str, forced_class_name: str,\n",
    "                               param_keys, params_phys_NxD, mask_D, id_start: int):\n",
    "    print(f\"\\n[{task_name}] Forced class = {forced_class_name}\")\n",
    "    used = mask_D > 0.5\n",
    "    used_keys = [k for k,u in zip(param_keys, used) if u]\n",
    "\n",
    "    for i in range(params_phys_NxD.shape[0]):\n",
    "        traj_id = id_start + i\n",
    "        parts = []\n",
    "        for j, k in enumerate(param_keys):\n",
    "            if used[j]:\n",
    "                parts.append(f\"{k}={params_phys_NxD[i,j]:.6g}\")\n",
    "        print(f\"  ID {traj_id:>3d}: \" + \", \".join(parts))\n",
    "\n",
    "\n",
    "def summarize_ranges(param_keys, params_phys_NxD, mask_D, qs=(5,50,95)):\n",
    "    used = mask_D > 0.5\n",
    "    print(\"\\nParameter ranges (percentiles) for forced class:\")\n",
    "    for j,k in enumerate(param_keys):\n",
    "        if not used[j]:\n",
    "            continue\n",
    "        vals = params_phys_NxD[:, j]\n",
    "        p = {q: float(np.percentile(vals, q)) for q in qs}\n",
    "        print(f\"  {k:>6s}: p5={p[5]:.6g}  p50={p[50]:.6g}  p95={p[95]:.6g}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# RUN EVERYTHING\n",
    "# =========================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "pk_arr = np.load(\"./final_inference_set/pkdata.npy\")  # (36,3,39)\n",
    "pd_arr = np.load(\"./final_inference_set/pddata.npy\")  # (48,3,25)\n",
    "\n",
    "pk_models = TG.build_pk_models(np.random.default_rng(0))\n",
    "pd_models = TG.build_pd_models(np.random.default_rng(0))\n",
    "pk_class_names = [m.name for m in pk_models]\n",
    "pd_class_names = [m.name for m in pd_models]\n",
    "pk_masks = np.stack([m.param_mask for m in pk_models], axis=0).astype(np.float32)\n",
    "pd_masks = np.stack([m.param_mask for m in pd_models], axis=0).astype(np.float32)\n",
    "pk_param_keys = TG.PK_PARAM_KEYS\n",
    "pd_param_keys = TG.PD_PARAM_KEYS\n",
    "\n",
    "# Load trained models\n",
    "pk_model, _, pk_xn, pk_yn = load_ckpt_build_model(\n",
    "    \"./long_runs/pk_deep/PK_long_deep_best.pt\", device, len(pk_class_names), len(pk_param_keys)\n",
    ")\n",
    "pd_model, _, pd_xn, pd_yn = load_ckpt_build_model(\n",
    "    \"./long_runs/pd_deep/PD_long_deep_best.pt\", device, len(pd_class_names), len(pd_param_keys)\n",
    ")\n",
    "\n",
    "# Times from your trial arrays\n",
    "pk_times = ensure_times(pk_arr[:,0,:], pk_arr.shape[2])\n",
    "pd_times = ensure_times(pd_arr[:,0,:], pd_arr.shape[2])\n",
    "\n",
    "# ---- Step 1: find most popular predicted class\n",
    "pk_probs = predict_class_probs(pk_arr, pk_model, device, pk_times, pk_xn, batch_size=64)\n",
    "pd_probs = predict_class_probs(pd_arr, pd_model, device, pd_times, pd_xn, batch_size=64)\n",
    "\n",
    "pk_pred = pk_probs.argmax(axis=1)\n",
    "pd_pred = pd_probs.argmax(axis=1)\n",
    "\n",
    "pk_counts = np.bincount(pk_pred, minlength=len(pk_class_names))\n",
    "pd_counts = np.bincount(pd_pred, minlength=len(pd_class_names))\n",
    "\n",
    "pk_best_id = int(pk_counts.argmax())\n",
    "pd_best_id = int(pd_counts.argmax())\n",
    "\n",
    "print(f\"[PK] most popular class = {pk_class_names[pk_best_id]} (id={pk_best_id}), counts={pk_counts.tolist()}\")\n",
    "print(f\"[PD] most popular class = {pd_class_names[pd_best_id]} (id={pd_best_id}), counts={pd_counts.tolist()}\")\n",
    "\n",
    "# ---- Step 2: FORCE all trajectories to use that classâ€™s mask, and decode params\n",
    "pk_forced = force_class_params_for_all(pk_arr, pk_model, device, pk_times, pk_xn, pk_yn, pk_masks, pk_best_id, batch_size=64)\n",
    "pd_forced = force_class_params_for_all(pd_arr, pd_model, device, pd_times, pd_xn, pd_yn, pd_masks, pd_best_id, batch_size=64)\n",
    "\n",
    "# ---- Step 3: print per-trajectory params\n",
    "print_per_trajectory_params(\n",
    "    task_name=\"PD\",\n",
    "    forced_class_name=pd_class_names[pd_best_id],\n",
    "    param_keys=pd_param_keys,\n",
    "    params_phys_NxD=pd_forced[\"forced_params_phys\"],\n",
    "    mask_D=pd_forced[\"forced_mask\"],\n",
    "    id_start=1\n",
    ")\n",
    "\n",
    "print_per_trajectory_params(\n",
    "    task_name=\"PK\",\n",
    "    forced_class_name=pk_class_names[pk_best_id],\n",
    "    param_keys=pk_param_keys,\n",
    "    params_phys_NxD=pk_forced[\"forced_params_phys\"],\n",
    "    mask_D=pk_forced[\"forced_mask\"],\n",
    "    id_start=13\n",
    ")\n",
    "\n",
    "# ---- Step 4: print summary ranges\n",
    "print(\"\\n[PD] Summary ranges\")\n",
    "summarize_ranges(pd_param_keys, pd_forced[\"forced_params_phys\"], pd_forced[\"forced_mask\"])\n",
    "\n",
    "print(\"\\n[PK] Summary ranges\")\n",
    "summarize_ranges(pk_param_keys, pk_forced[\"forced_params_phys\"], pk_forced[\"forced_mask\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc6235-a4c4-4f40-a47b-806bae31748c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MY_GPU",
   "language": "python",
   "name": "rl_agent_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
