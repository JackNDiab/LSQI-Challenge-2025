{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0c70be-b654-4a15-8341-a8f10162b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import ClassicalPredictor as CP\n",
    "import TrajectoryGenerator as TG\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Normalizer reconstruction\n",
    "# -------------------------\n",
    "class XNorm:\n",
    "    def __init__(self, mean, std, log1p=True, eps=1e-6):\n",
    "        self.mean = np.asarray(mean, dtype=np.float32)\n",
    "        self.std  = np.maximum(np.asarray(std, dtype=np.float32), eps)\n",
    "        self.log1p = bool(log1p)\n",
    "\n",
    "    def transform(self, X_NTxC: np.ndarray) -> np.ndarray:\n",
    "        # X: (N,T,C)\n",
    "        X = X_NTxC.astype(np.float32, copy=False)\n",
    "        if self.log1p:\n",
    "            X = np.log1p(np.clip(X, 0.0, None))\n",
    "        return (X - self.mean[None, None, :]) / self.std[None, None, :]\n",
    "\n",
    "\n",
    "class YNorm:\n",
    "    \"\"\"\n",
    "    In training you did:\n",
    "      y_norm[used] = (log(y_phys[used]) - mean[used]) / std[used]\n",
    "    So inverse is:\n",
    "      y_phys = exp(y_norm * std + mean)  (then zero-out unused)\n",
    "    \"\"\"\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = np.asarray(mean, dtype=np.float32)\n",
    "        self.std  = np.maximum(np.asarray(std, dtype=np.float32), 1e-6)\n",
    "\n",
    "    def inverse(self, y_norm_NxD: np.ndarray, mask_NxD: np.ndarray) -> np.ndarray:\n",
    "        y_norm_NxD = np.asarray(y_norm_NxD, dtype=np.float32)\n",
    "        mask_NxD   = np.asarray(mask_NxD, dtype=np.float32)\n",
    "        # compute full exp then mask out unused dims\n",
    "        y_phys = np.exp(y_norm_NxD * self.std[None, :] + self.mean[None, :]).astype(np.float32)\n",
    "        y_phys *= mask_NxD\n",
    "        return y_phys\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def ensure_times(times_NxT: np.ndarray, expected_T: int) -> np.ndarray:\n",
    "    if times_NxT.shape[1] != expected_T:\n",
    "        raise ValueError(f\"Expected T={expected_T}, got {times_NxT.shape[1]}\")\n",
    "    return times_NxT[0].astype(np.float32)  # assume common grid\n",
    "\n",
    "\n",
    "def load_ckpt_build_model(ckpt_path: str, device, num_classes: int, reg_dim: int):\n",
    "    ckpt = torch.load(ckpt_path, map_location=device)\n",
    "    cfg = ckpt[\"cfg\"]\n",
    "\n",
    "    model = CP.MultiTaskTransformer(\n",
    "        input_dim=2,\n",
    "        num_classes=num_classes,\n",
    "        reg_dim=reg_dim,\n",
    "        d_model=cfg[\"d_model\"],\n",
    "        nhead=cfg[\"nhead\"],\n",
    "        num_layers=cfg[\"num_layers\"],\n",
    "        dim_feedforward=cfg[\"dim_feedforward\"],\n",
    "        dropout=cfg[\"dropout\"],\n",
    "    ).to(device)\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    model.eval()\n",
    "\n",
    "    # norms (strongly recommended; otherwise accuracy will drop)\n",
    "    if (\"x_norm\" not in ckpt) or (ckpt[\"x_norm\"] is None):\n",
    "        raise RuntimeError(f\"{ckpt_path} does not contain x_norm. Re-save ckpts with x_norm/y_norm.\")\n",
    "    if (\"y_norm\" not in ckpt) or (ckpt[\"y_norm\"] is None):\n",
    "        raise RuntimeError(f\"{ckpt_path} does not contain y_norm. Re-save ckpts with x_norm/y_norm.\")\n",
    "\n",
    "    x_norm = XNorm(\n",
    "        mean=np.array(ckpt[\"x_norm\"][\"mean\"]),\n",
    "        std=np.array(ckpt[\"x_norm\"][\"std\"]),\n",
    "        log1p=ckpt[\"x_norm\"].get(\"log1p\", True),\n",
    "    )\n",
    "    y_norm = YNorm(\n",
    "        mean=np.array(ckpt[\"y_norm\"][\"mean\"]),\n",
    "        std=np.array(ckpt[\"y_norm\"][\"std\"]),\n",
    "    )\n",
    "\n",
    "    return model, cfg, x_norm, y_norm\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_logits_and_regnorm(\n",
    "    arr_Nx3xT: np.ndarray,\n",
    "    model,\n",
    "    device,\n",
    "    times_T: np.ndarray,\n",
    "    x_norm: XNorm,\n",
    "    batch_size: int = 256,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      probs (N,K), pred_cls (N,), yhat_norm (N,D)\n",
    "    \"\"\"\n",
    "    assert arr_Nx3xT.ndim == 3 and arr_Nx3xT.shape[1] == 3\n",
    "    N, _, T = arr_Nx3xT.shape\n",
    "\n",
    "    # features: (dose, conc) or (conc, biom) => (N,T,2)\n",
    "    X = np.transpose(arr_Nx3xT[:, 1:3, :], (0, 2, 1)).astype(np.float32)  # (N,T,2)\n",
    "    X = x_norm.transform(X)\n",
    "\n",
    "    times_t = torch.tensor(times_T, dtype=torch.float32, device=device)\n",
    "\n",
    "    probs_all = []\n",
    "    cls_all = []\n",
    "    yhat_all = []\n",
    "\n",
    "    for s in range(0, N, batch_size):\n",
    "        e = min(N, s + batch_size)\n",
    "        xb = torch.from_numpy(X[s:e]).to(device, non_blocking=True)\n",
    "        logits, yhat_norm = model(xb, times_t)\n",
    "        probs = F.softmax(logits, dim=1).cpu().numpy().astype(np.float32)\n",
    "        pred_cls = probs.argmax(axis=1).astype(np.int64)\n",
    "\n",
    "        probs_all.append(probs)\n",
    "        cls_all.append(pred_cls)\n",
    "        yhat_all.append(yhat_norm.cpu().numpy().astype(np.float32))\n",
    "\n",
    "    return (\n",
    "        np.concatenate(probs_all, axis=0),\n",
    "        np.concatenate(cls_all, axis=0),\n",
    "        np.concatenate(yhat_all, axis=0),\n",
    "    )\n",
    "\n",
    "\n",
    "def summarize_ranges(params_NxD: np.ndarray, mask_D: np.ndarray, keys: list, qs=(5, 50, 95)):\n",
    "    out = {}\n",
    "    used = mask_D > 0.5\n",
    "    for j, k in enumerate(keys):\n",
    "        if not used[j]:\n",
    "            continue\n",
    "        vals = params_NxD[:, j]\n",
    "        out[k] = {f\"p{q}\": float(np.percentile(vals, q)) for q in qs}\n",
    "    return out\n",
    "\n",
    "\n",
    "def explain_best_class_for_all(\n",
    "    probs_NxK: np.ndarray,\n",
    "    pred_cls_N: np.ndarray,\n",
    "    yhat_norm_NxD: np.ndarray,\n",
    "    y_norm: YNorm,\n",
    "    class_names: list[str],\n",
    "    class_masks_KxD: np.ndarray,\n",
    "    param_keys: list[str],\n",
    "):\n",
    "    \"\"\"\n",
    "    1) most popular predicted class\n",
    "    2) treat ALL trajectories as that class => invert params using that class mask\n",
    "    3) summarize parameter ranges\n",
    "    \"\"\"\n",
    "    K = len(class_names)\n",
    "    counts = np.bincount(pred_cls_N, minlength=K)\n",
    "    best_k = int(counts.argmax())\n",
    "    best_name = class_names[best_k]\n",
    "    best_mask = class_masks_KxD[best_k].astype(np.float32)\n",
    "\n",
    "    # apply best_mask to all\n",
    "    mask_all = np.repeat(best_mask[None, :], repeats=yhat_norm_NxD.shape[0], axis=0)\n",
    "    params_phys_all = y_norm.inverse(yhat_norm_NxD, mask_all)\n",
    "\n",
    "    summary = {\n",
    "        \"most_popular_class\": best_name,\n",
    "        \"most_popular_class_id\": best_k,\n",
    "        \"class_counts\": {class_names[i]: int(counts[i]) for i in range(K) if counts[i] > 0},\n",
    "        \"param_ranges_p5_p50_p95\": summarize_ranges(params_phys_all, best_mask, param_keys, qs=(5,50,95)),\n",
    "    }\n",
    "    return summary, params_phys_all, best_k\n",
    "\n",
    "\n",
    "def run_trial_explain(\n",
    "    pk_npy: str,\n",
    "    pd_npy: str,\n",
    "    pk_ckpt: str,\n",
    "    pd_ckpt: str,\n",
    "    out_json: str = \"./final_inference_set/pkpd_bestclass_summary.json\",\n",
    "    out_npz: str  = \"./final_inference_set/pkpd_bestclass_params.npz\",\n",
    "    batch_size: int = 64,\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    pk_arr = np.load(pk_npy)  # (N,3,39)\n",
    "    pd_arr = np.load(pd_npy)  # (N,3,25)\n",
    "\n",
    "    pk_times = ensure_times(pk_arr[:, 0, :], pk_arr.shape[2])\n",
    "    pd_times = ensure_times(pd_arr[:, 0, :], pd_arr.shape[2])\n",
    "\n",
    "    # class libraries + masks\n",
    "    pk_models = TG.build_pk_models(np.random.default_rng(0))\n",
    "    pd_models = TG.build_pd_models(np.random.default_rng(0))\n",
    "    pk_names = [m.name for m in pk_models]\n",
    "    pd_names = [m.name for m in pd_models]\n",
    "    pk_masks = np.stack([m.param_mask for m in pk_models], axis=0).astype(np.float32)\n",
    "    pd_masks = np.stack([m.param_mask for m in pd_models], axis=0).astype(np.float32)\n",
    "\n",
    "    pk_param_keys = TG.PK_PARAM_KEYS\n",
    "    pd_param_keys = TG.PD_PARAM_KEYS\n",
    "\n",
    "    # load models + norms\n",
    "    pk_model, _, pk_xnorm, pk_ynorm = load_ckpt_build_model(pk_ckpt, device, len(pk_names), len(pk_param_keys))\n",
    "    pd_model, _, pd_xnorm, pd_ynorm = load_ckpt_build_model(pd_ckpt, device, len(pd_names), len(pd_param_keys))\n",
    "\n",
    "    # run inference (logits + regnorm)\n",
    "    pk_probs, pk_pred_cls, pk_yhat_norm = run_logits_and_regnorm(pk_arr, pk_model, device, pk_times, pk_xnorm, batch_size)\n",
    "    pd_probs, pd_pred_cls, pd_yhat_norm = run_logits_and_regnorm(pd_arr, pd_model, device, pd_times, pd_xnorm, batch_size)\n",
    "\n",
    "    # explain “best class for all”\n",
    "    pk_summary, pk_params_all, pk_best_k = explain_best_class_for_all(\n",
    "        pk_probs, pk_pred_cls, pk_yhat_norm, pk_ynorm, pk_names, pk_masks, pk_param_keys\n",
    "    )\n",
    "    pd_summary, pd_params_all, pd_best_k = explain_best_class_for_all(\n",
    "        pd_probs, pd_pred_cls, pd_yhat_norm, pd_ynorm, pd_names, pd_masks, pd_param_keys\n",
    "    )\n",
    "\n",
    "    # write outputs\n",
    "    os.makedirs(os.path.dirname(out_json), exist_ok=True)\n",
    "    with open(out_json, \"w\") as f:\n",
    "        json.dump({\"pk\": pk_summary, \"pd\": pd_summary}, f, indent=2)\n",
    "\n",
    "    np.savez(\n",
    "        out_npz,\n",
    "        pk_pred_cls=pk_pred_cls,\n",
    "        pk_probs=pk_probs,\n",
    "        pk_best_class_id=pk_best_k,\n",
    "        pk_bestclass_params_phys=pk_params_all,  # (N, Dpk), masked dims kept, others 0\n",
    "        pd_pred_cls=pd_pred_cls,\n",
    "        pd_probs=pd_probs,\n",
    "        pd_best_class_id=pd_best_k,\n",
    "        pd_bestclass_params_phys=pd_params_all,  # (N, Dpd), masked dims kept, others 0\n",
    "    )\n",
    "\n",
    "    print(\"Wrote:\", out_json)\n",
    "    print(\"Wrote:\", out_npz)\n",
    "\n",
    "    print(\"\\n[PK] most popular class:\", pk_summary[\"most_popular_class\"], \"counts:\", pk_summary[\"class_counts\"])\n",
    "    print(\"[PK] param ranges:\", pk_summary[\"param_ranges_p5_p50_p95\"])\n",
    "\n",
    "    print(\"\\n[PD] most popular class:\", pd_summary[\"most_popular_class\"], \"counts:\", pd_summary[\"class_counts\"])\n",
    "    print(\"[PD] param ranges:\", pd_summary[\"param_ranges_p5_p50_p95\"])\n",
    "\n",
    "    return {\"pk\": pk_summary, \"pd\": pd_summary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "588d7697-2c5a-4ce5-b254-bb68ad085470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary_block(kind: str, summary: dict):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"{kind.upper()} SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    print(f\"Most popular class: {summary['most_popular_class']} (id={summary['most_popular_class_id']})\")\n",
    "    print(\"\\nClass counts:\")\n",
    "    for k, v in sorted(summary[\"class_counts\"].items(), key=lambda kv: -kv[1]):\n",
    "        print(f\"  {k:>24s} : {v}\")\n",
    "\n",
    "    print(\"\\nParameter ranges (p5 / p50 / p95) for MOST popular class:\")\n",
    "    pr = summary[\"param_ranges_p5_p50_p95\"]\n",
    "    if not pr:\n",
    "        print(\"  (no parameters active for this class?)\")\n",
    "    else:\n",
    "        for p_name, qs in pr.items():\n",
    "            p5  = qs.get(\"p5\", None)\n",
    "            p50 = qs.get(\"p50\", None)\n",
    "            p95 = qs.get(\"p95\", None)\n",
    "            print(f\"  {p_name:>10s} : {p5:.6g} / {p50:.6g} / {p95:.6g}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bd44181-84d7-432c-9236-a3aa4c23cdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: ./final_inference_set/pkpd_bestclass_summary.json\n",
      "Wrote: ./final_inference_set/pkpd_bestclass_params.npz\n",
      "\n",
      "[PK] most popular class: pk_2c_iv_infusion counts: {'pk_2c_iv_infusion': 36}\n",
      "[PK] param ranges: {'CL': {'p5': 0.02954680845141411, 'p50': 0.048646895214915276, 'p95': 0.0873776227235794}, 'Vc': {'p5': 1.1349785327911377, 'p50': 1.3215688467025757, 'p95': 1.543166697025299}, 'Vp': {'p5': 6.172096490859985, 'p50': 8.03603458404541, 'p95': 10.4442298412323}, 'Q': {'p5': 0.1753370277583599, 'p50': 0.33222708106040955, 'p95': 0.7330343127250671}, 'tau': {'p5': 3.435567319393158, 'p50': 5.0334038734436035, 'p95': 6.821564316749573}}\n",
      "\n",
      "[PD] most popular class: pd_indirect_inhib_kin counts: {'pd_direct_linear': 1, 'pd_direct_emax': 1, 'pd_direct_sigmoid': 3, 'pd_effect_comp_emax': 2, 'pd_indirect_inhib_kin': 35, 'pd_indirect_stim_kin': 3, 'pd_indirect_inhib_kout': 1, 'pd_indirect_stim_kout': 1, 'pd_transit_delay': 1}\n",
      "[PD] param ranges: {'R0': {'p5': 5.926348447799683, 'p50': 8.75716495513916, 'p95': 11.174081087112427}, 'IC50': {'p5': 5.720919346809387, 'p50': 9.189297199249268, 'p95': 18.591414737701417}, 'kin': {'p5': 0.49938725084066393, 'p50': 0.8473046123981476, 'p95': 1.4583324790000916}, 'kout': {'p5': 0.06240067724138498, 'p50': 0.10621953010559082, 'p95': 0.13863920122385026}}\n",
      "\n",
      "================================================================================\n",
      "PK SUMMARY\n",
      "================================================================================\n",
      "Most popular class: pk_2c_iv_infusion (id=5)\n",
      "\n",
      "Class counts:\n",
      "         pk_2c_iv_infusion : 36\n",
      "\n",
      "Parameter ranges (p5 / p50 / p95) for MOST popular class:\n",
      "          CL : 0.0295468 / 0.0486469 / 0.0873776\n",
      "          Vc : 1.13498 / 1.32157 / 1.54317\n",
      "          Vp : 6.1721 / 8.03603 / 10.4442\n",
      "           Q : 0.175337 / 0.332227 / 0.733034\n",
      "         tau : 3.43557 / 5.0334 / 6.82156\n",
      "\n",
      "================================================================================\n",
      "PD SUMMARY\n",
      "================================================================================\n",
      "Most popular class: pd_indirect_inhib_kin (id=5)\n",
      "\n",
      "Class counts:\n",
      "     pd_indirect_inhib_kin : 35\n",
      "         pd_direct_sigmoid : 3\n",
      "      pd_indirect_stim_kin : 3\n",
      "       pd_effect_comp_emax : 2\n",
      "          pd_direct_linear : 1\n",
      "            pd_direct_emax : 1\n",
      "    pd_indirect_inhib_kout : 1\n",
      "     pd_indirect_stim_kout : 1\n",
      "          pd_transit_delay : 1\n",
      "\n",
      "Parameter ranges (p5 / p50 / p95) for MOST popular class:\n",
      "          R0 : 5.92635 / 8.75716 / 11.1741\n",
      "        IC50 : 5.72092 / 9.1893 / 18.5914\n",
      "         kin : 0.499387 / 0.847305 / 1.45833\n",
      "        kout : 0.0624007 / 0.10622 / 0.138639\n"
     ]
    }
   ],
   "source": [
    "pk_npy_path = \"./final_inference_set/pkdata.npy\"\n",
    "pd_npy_path = \"./final_inference_set/pddata.npy\"\n",
    "pk_ckpt_path = \"./long_runs/pk_deep/PK_long_deep_best.pt\"\n",
    "pd_ckpt_path = \"./long_runs/pd_deep/PD_long_deep_best.pt\"\n",
    "\n",
    "\n",
    "# ---- after you run run_trial_explain(...) ----\n",
    "out = run_trial_explain(\n",
    "    pk_npy=pk_npy_path,\n",
    "    pd_npy=pd_npy_path,\n",
    "    pk_ckpt=pk_ckpt_path,\n",
    "    pd_ckpt=pd_ckpt_path,\n",
    "    out_json=\"./final_inference_set/pkpd_bestclass_summary.json\",\n",
    "    out_npz=\"./final_inference_set/pkpd_bestclass_params.npz\",\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "print_summary_block(\"pk\", out[\"pk\"])\n",
    "print_summary_block(\"pd\", out[\"pd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe634d-8d59-4964-8b18-ef335662cc41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MY_GPU",
   "language": "python",
   "name": "rl_agent_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
